{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2543de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.svm import LinearSVR\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold, KFold, GridSearchCV\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "global scoring\n",
    "scoring = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a1ab3",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653943dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(baseregresor):\n",
    "    if baseregresor == 'lr':\n",
    "        return LinearRegression()\n",
    "    if baseregresor == 'knn':\n",
    "        return KNeighborsRegressor()\n",
    "    if baseregresor == 'rfr':\n",
    "        return RandomForestRegressor()\n",
    "    if baseregresor == 'svr':\n",
    "        return LinearSVR(max_iter=100000)\n",
    "\n",
    "def get_param_grid(clf_method):\n",
    "    \"\"\" given a keyword describing the model type, this\n",
    "    function returns the parameter grid and the baseline\n",
    "    model object.\n",
    "    \"\"\"\n",
    "    clf, params = None, []\n",
    "    if clf_method == 'svr':\n",
    "        clf = LinearSVR(max_iter=100000)\n",
    "        params = [{'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                  'C' : [0.1, 0.5, 1, 5, 10],\n",
    "                  'degree' : [3,8],\n",
    "                  'gamma' : ['auto','scale']\n",
    "                  }]\n",
    "    \n",
    "    if clf_method == 'rfr':\n",
    "        clf = RandomForestRegressor()\n",
    "        params = [{\n",
    "                'n_estimators': [100, 150, 200],\n",
    "                'max_depth': [1, 2, 3],\n",
    "                'bootstrap': [True],\n",
    "                'min_samples_split': [5, 10]\n",
    "                }] \n",
    "    if clf_method == 'lr':\n",
    "        clf = LinearRegression()\n",
    "        params = None\n",
    "    if clf_method == 'knn':\n",
    "        clf = KNeighborsRegressor()\n",
    "        params = None\n",
    "    print('estimator:', clf.__class__.__name__)\n",
    "    return clf, params\n",
    "\n",
    "def get_best_params(X, y, estimator, paramgrid, nfolds, scoring=scoring):\n",
    "    \"\"\"Find the best set of parameter for a given estimator and parameter grid\n",
    "    using cross validation and grid search.\n",
    "    \"\"\"\n",
    "    cv = KFold(n_splits=nfolds)\n",
    "    search = GridSearchCV(estimator, paramgrid, scoring=scoring, cv=cv)\n",
    "    gs = search.fit(X, y)\n",
    "    best_params = gs.best_params_\n",
    "    print('best params for %s:'% estimator.__class__.__name__)\n",
    "    print (best_params)\n",
    "    return best_params\n",
    "\n",
    "def get_repeat_cv_scores(X, y, model, nfolds, nrepeats, scoring=scoring):\n",
    " \n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=nfolds, n_repeats=nrepeats, random_state=1)\n",
    "    \n",
    "    # evaluate the model and collect the scores\n",
    "    n_scores = cross_val_score(model, \n",
    "                               X, y, \n",
    "                               scoring=scoring, \n",
    "                               cv=cv, \n",
    "                               n_jobs=-1)\n",
    "    \n",
    "    # force the scores to be positive\n",
    "    n_scores = absolute(n_scores)\n",
    "\n",
    "    return mean(n_scores), std(n_scores)\n",
    "\n",
    "def get_direct_multi_output_regression_model(modeltag, params):\n",
    "    \"\"\" Some regression machine learning algorithms support multiple outputs directly.\n",
    "    This includes most of the popular machine learning algorithms implemented in the\n",
    "    scikit-learn library, such as: LinearRegression, KNeighborsRegressor,\n",
    "    DecisionTreeRegressor, RandomForestRegressor. \n",
    "    \n",
    "    Given a modeltag (keyword to identify estimator type), and a set of parameters,\n",
    "    this wrapper function returns the model object.\n",
    "    \"\"\"\n",
    "    \n",
    "    if modeltag not in ['lr', 'knn', 'rfr', 'dtr']:\n",
    "        print('cant do direct multioutputregression for %s' % modeltag)\n",
    "        return None\n",
    "    \n",
    "    # define model\n",
    "    model = get_base_model(modeltag)\n",
    "    if params is not None:\n",
    "        print('params:', params)\n",
    "        model.set_params(**params)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def get_wrapper_multi_output_regression_model(modeltag, params):\n",
    "    \"\"\"\n",
    "    Not all regression algorithms support multioutput regression.\n",
    "    One example is the support vector regressor.\n",
    "    A workaround for using regression models designed for predicting one value for \n",
    "    multioutput regression is to divide the multioutput regression problem into \n",
    "    multiple sub-problems.\n",
    "    \n",
    "    Given a modeltag (keyword to identify estimator type), and a set of parameters,\n",
    "    this wrapper function returns the model object using this approach.\n",
    "    \"\"\"\n",
    "    if modeltag not in ['svr', 'lr', 'knn', 'rfr', 'dtr']:\n",
    "        print('cant do direct multioutputregression for %s' % modeltag)\n",
    "        return None\n",
    "    \n",
    "    # define model\n",
    "    model = get_base_model(modeltag)\n",
    "    if params is not None:\n",
    "        print('params:', params)\n",
    "        model.set_params(**params)\n",
    "    \n",
    "    wrapper = MultiOutputRegressor(model)\n",
    "    return wrapper\n",
    "    \n",
    "def get_chain_multi_output_regression_model(modeltag, params, order):\n",
    "    \"\"\"\n",
    "    Another approach to using single-output regression models for multioutput regression is\n",
    "    to create a linear sequence of models.\n",
    "\n",
    "    The first model in the sequence uses the input and predicts one output; the second model\n",
    "    uses the input and the output from the first model to make a prediction; and so on.\n",
    "    \n",
    "    Given a modeltag (keyword to identify estimator type), and a set of parameters,\n",
    "    this wrapper function returns the model object using this approach.\n",
    "    \"\"\"\n",
    "    if modeltag not in ['svr', 'lr', 'knn', 'rfr', 'dtr']:\n",
    "        print('cant do direct multioutputregression for %s' % modeltag)\n",
    "        return None\n",
    "    \n",
    "    # define model\n",
    "    model = get_base_model(modeltag)\n",
    "    if params is not None:\n",
    "        print('params:', params)\n",
    "        model.set_params(**params)\n",
    "   \n",
    "    print('chain order:', order)\n",
    "    wrapper = RegressorChain(model,order=order)\n",
    "    return wrapper\n",
    "    \n",
    "def standardize_features(df, featurelist):\n",
    "    \"\"\"\n",
    "    force features to have 0 mean and unit std. \n",
    "    returns scaled df and the scaler(for use on test set)\n",
    "    \n",
    "    \"\"\"\n",
    "    print('standardization feature scaling')\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    ftrVals = scaler.fit_transform(df)\n",
    "    out_df = pd.DataFrame(ftrVals, columns=featurelist, index=df.index.values)\n",
    "   \n",
    "    return out_df, scaler\n",
    "\n",
    "def normalize_features(df, featurelist):\n",
    "    \"\"\"\n",
    "    force features to be between 0-1 (aka min-max scaling). \n",
    "    returns scaled df and the scaler(for use on test set)\n",
    "    \"\"\"\n",
    "    print('min-max feature scaling')\n",
    "    scaler = MinMaxScaler()\n",
    "    ftrVals = scaler.fit_transform(df)\n",
    "    out_df = pd.DataFrame(ftrVals, columns=featurelist, index=df.index.values)\n",
    "    return out_df, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27dd6c",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cc065",
   "metadata": {},
   "source": [
    "### run this cell for loading the data for predicting A-B-C scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment the line above if you want to run this cell\n",
    "\n",
    "foldername = 'ABCscores-standardizedftrvals-originaltargetvals'\n",
    "csvname =  '__.csv'\n",
    "\n",
    "input_dir = os.getcwd() \n",
    "csvpath = os.path.join(input_dir, csvname)\n",
    "output_dir = os.path.join(input_dir, foldername)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print('input_dir:', input_dir)\n",
    "print('output_dir:', output_dir, '\\n')\n",
    "\n",
    "df = pd.read_csv(csvpath)\n",
    "indexcol = 'SampleID'\n",
    "ftrcols = ['Enhancing','RCBV.Raw_Mean', 'RCBV.Raw_Std', 'FA.Raw_Std', \n",
    "           'FA.Raw_Mean', 'MD.Raw_Mean', 'MD.Raw_Std', 'EPI.Raw_Mean', \n",
    "           'EPI.Raw_Std', 'CenterFecsT2', 'MeanFecsT2', 'StdFecsT2']\n",
    "\n",
    "targetcols = ['ScoreA', 'ScoreB', 'ScoreC']\n",
    "\n",
    "df['Enhancing'].replace(['ENH', 'BAT', 'NEC', 'Central Cyst/Cavity'], [0, 1, 2, 3], inplace=True)\n",
    "df.set_index(indexcol, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "X = df.loc[:, ftrcols]\n",
    "\n",
    "if 'standardizedftrvals' in foldername: \n",
    "    X, _ = standardize_features(X, ftrcols)\n",
    "    print(X.head())\n",
    "\n",
    "elif 'originalftrvals' in foldername:\n",
    "    print('no feature manipulation')\n",
    "    \n",
    "else:\n",
    "    print('feature preprocessing unknown!! fix this!!')\n",
    "    X = None # set it to none so the code doesnt just run\n",
    "    \n",
    "y = df.loc[:, targetcols]\n",
    "\n",
    "if 'normalizedtargetvals' in foldername:\n",
    "    y, _ = normalize_features(y, targetcols)\n",
    "    print(y.head())\n",
    "    \n",
    "elif 'originaltargetvals' in foldername:\n",
    "    print('no target column manipulation')\n",
    "    \n",
    "else:\n",
    "    print('target column preprocessing unknown!! fix this')\n",
    "    y = None\n",
    "\n",
    "print('\\n', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584183b5",
   "metadata": {},
   "source": [
    "### OR run this cell for loading the data for predicting glMes-glPro-glPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9dfd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = 'GLs-originalftrvals'\n",
    "csvname =  '__.csv'\n",
    "\n",
    "run_wrapperregression = False\n",
    "run_chainregression = False\n",
    "run_directregression = True\n",
    "\n",
    "input_dir = os.getcwd() \n",
    "csvpath = os.path.join(input_dir, csvname)\n",
    "output_dir = os.path.join(input_dir, foldername)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "print('input_dir:', input_dir)\n",
    "print('output_dir:', output_dir)\n",
    "\n",
    "# set index\n",
    "indexcol = 'SampleID'\n",
    "df = pd.read_csv(csvpath)\n",
    "df.set_index(indexcol, inplace=True)\n",
    "\n",
    "# composite columns\n",
    "targetcols = ['gl_Mes', 'gl_PN']\n",
    "\n",
    "print('\\ncreating', targetcols)\n",
    "df['gl_Mes'] = np.NaN\n",
    "df['gl_PN'] = np.NaN\n",
    "df['gl_Pro'] = np.NaN\n",
    "for i in df.index.values:\n",
    "        \n",
    "    glmes1 = df.loc[i, 'gl_Mes1']\n",
    "    glmes2 = df.loc[i, 'gl_Mes2']\n",
    "\n",
    "    glPro1 = df.loc[i, 'gl_Pro1']\n",
    "    glPro2 = df.loc[i, 'gl_Pro1']\n",
    "\n",
    "    glPN1  = df.loc[i, 'gl_PN1']\n",
    "    glPN2  = df.loc[i, 'gl_PN2']\n",
    "    \n",
    "    sum_gls = glmes1 + glmes2 + glPro1 + glPro2 + glPN1 + glPN2\n",
    "    df.loc[i, 'gl_Mes'] = (glmes1 + glmes2) / sum_gls\n",
    "    df.loc[i, 'gl_PN'] = (glPN1 + glPN2) / sum_gls\n",
    "    \n",
    "\n",
    "# clean up\n",
    "ftrcols = ['Enhancing','RCBV.Raw_Mean', 'RCBV.Raw_Std', 'FA.Raw_Std', \n",
    "           'FA.Raw_Mean', 'MD.Raw_Mean', 'MD.Raw_Std', 'EPI.Raw_Mean', \n",
    "           'EPI.Raw_Std', 'CenterFecsT2', 'MeanFecsT2', 'StdFecsT2']\n",
    "\n",
    "if 'ENH' in set(df['Enhancing'].values):\n",
    "    df['Enhancing'].replace(['ENH', 'BAT', 'NEC', 'Central Cyst/Cavity'], [0, 1, 2, 3], inplace=True)\n",
    "\n",
    "df = df[ftrcols+targetcols]\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75bbeda",
   "metadata": {},
   "source": [
    "#### separate X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e79f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ftrcols]\n",
    "\n",
    "if 'standardizedftrvals' in foldername: \n",
    "    X, _ = standardize_features(X, ftrcols)\n",
    "    print(X.head())\n",
    "\n",
    "elif 'originalftrvals' in foldername:\n",
    "    print('\\nno feature manipulation')\n",
    "    \n",
    "else:\n",
    "    print('feature preprocessing unknown!! fix this!!')\n",
    "    X = None # set it to none so the code doesnt just run\n",
    "    \n",
    "y = df.loc[:, targetcols]\n",
    "\n",
    "print('\\n', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8293a5a",
   "metadata": {},
   "source": [
    "#### visualize target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e66d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "for col in y.columns.values:\n",
    "    fig = plt.figure(figsize=(2, 3))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax = sns.boxplot(y=col, data=df, palette=\"Greens\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b552a",
   "metadata": {},
   "source": [
    "## direct multioutputregressionn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243502c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds = 5 \n",
    "nrepeats = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c236b",
   "metadata": {},
   "source": [
    "#### get cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = os.path.join(output_dir, 'direct_multi_output_regression')\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "### train cv model\n",
    "for regtype in ['rfr']:\n",
    "    \n",
    "    fold_count = 0\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    truthcolnames = list(y.columns.values) \n",
    "    predcolnames = [v + '_pred' for v in truthcolnames]\n",
    "    pred_df = pd.DataFrame(index=X.index.values, columns=truthcolnames+predcolnames)\n",
    "    \n",
    "    for train_ix, test_ix in cv_outer.split(X, y):\n",
    "\n",
    "        print('\\nfold', fold_count)\n",
    "        X_train = X.iloc[train_ix]\n",
    "        X_test  = X.iloc[test_ix]\n",
    "        y_train = y.iloc[train_ix]\n",
    "        y_test  = y.iloc[test_ix]\n",
    "        \n",
    "        testset_indices = X.index.values[test_ix]\n",
    "        \n",
    "        \n",
    "        # tune \n",
    "        estimator, paramgrd = get_param_grid(regtype)\n",
    "        if paramgrd is not None:\n",
    "            print('tuning params for %s..' % estimator.__class__.__name__)\n",
    "            best_params = get_best_params(X, y, estimator, paramgrd, nfolds)\n",
    "        else:\n",
    "            best_params = None\n",
    "        \n",
    "        model = get_direct_multi_output_regression_model(regtype, best_params)\n",
    "        mean_s, std_s = get_repeat_cv_scores(X_train, y_train, model, nfolds, nrepeats)\n",
    "        print('MAE of %s in gridsearch:\\t%.3f (%.3f)' % (model.__class__.__name__, mean_s, std_s))\n",
    "\n",
    "\n",
    "        # train\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # test \n",
    "        yhat = model.predict(X_test)\n",
    "\n",
    "        # save predictions\n",
    "        pred_df.loc[testset_indices, truthcolnames] = y_test\n",
    "        pred_df.loc[testset_indices, predcolnames ] = yhat\n",
    "        fold_count += 1\n",
    "\n",
    "    print(pred_df.head())\n",
    "    outputcsvpath = os.path.join(savedir, estimator.__class__.__name__+'_predictions.csv')\n",
    "    pred_df.to_csv(outputcsvpath)\n",
    "    print(outputcsvpath)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3cd62",
   "metadata": {},
   "source": [
    "#### create plot of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aeb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predDir = os.path.join(output_dir, 'direct_multi_output_regression')\n",
    "figDir =  output_dir\n",
    "for csv in os.listdir(predDir):\n",
    "    if '_predictions.csv' in csv:\n",
    "        \n",
    "        csvpath = os.path.join(predDir, csv)\n",
    "        estimator = csv.split('_')[0]\n",
    "        df = pd.read_csv(csvpath)\n",
    "        df = df.rename(columns={'Unnamed: 0':indexcol})\n",
    "        df.set_index(indexcol, inplace=True)\n",
    "        \n",
    "        #fig = plt.figure(figsize=(len(scorecols)*4, 3))\n",
    "        \n",
    "        for n, col in enumerate(y.columns.values):\n",
    "            \n",
    "            #ax = fig.add_subplot( 1, 3, n+1)\n",
    "            g = sns.lmplot(y=col, x=col+'_pred', data=df)\n",
    "            r, p = stats.pearsonr(df[col], df[col+'_pred'])\n",
    "            g.fig.text(.2, .9, 'r={:.2f}, p={:.2g}'.format(r, p), fontsize=14)\n",
    "            #plt.xlim([0.12,0.6])\n",
    "            #plt.ylim([0.0,0.8])\n",
    "            plt.xticks([0.15,0.25,0.35,.45, 0.55],fontsize=15)\n",
    "            plt.yticks(fontsize=15)\n",
    "            plt.xlabel('\\npredicted glPN')\n",
    "            plt.ylabel('\\nactual glPN')\n",
    "            plt.show()\n",
    "            \n",
    "            figname = '-'.join([s for s in ['direct', estimator, col, 'lmplot.jpg']])\n",
    "            g.fig.savefig(os.path.join(figDir, figname), bbox_inches='tight', pad_inches=1, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0aa338",
   "metadata": {},
   "source": [
    "## Wrapper Multioutput Regression Algorithms\n",
    "hyperparam tuning is different here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb671b",
   "metadata": {},
   "source": [
    "#### get cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de6667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = os.path.join(output_dir, 'wrapper_multi_output_regression')\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "regtype='svr'\n",
    "estimator = get_base_model(regtype)\n",
    "c_grid = [0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "\n",
    "fold_count = 0\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "truthcolnames = list(y.columns.values) \n",
    "predcolnames = [x + '_pred' for x in truthcolnames]\n",
    "pred_df = pd.DataFrame(index=X.index.values, columns=truthcolnames+predcolnames)\n",
    "\n",
    "for train_ix, test_ix in cv_outer.split(X, y):\n",
    "\n",
    "    print('\\nfold', fold_count)\n",
    "    X_train = X.iloc[train_ix]\n",
    "    X_test  = X.iloc[test_ix]\n",
    "    y_train = y.iloc[train_ix]\n",
    "    y_test  = y.iloc[test_ix]\n",
    "    testset_indices = X.index.values[test_ix]\n",
    "\n",
    "    # tuning is a bit manual in this case\n",
    "    # havenot found a way to make it work the traditional way (above)\n",
    "    scores = []\n",
    "    for c in c_grid:\n",
    "        params = {'C':c}\n",
    "        model = get_wrapper_multi_output_regression_model(regtype, params)\n",
    "        mean_s, std_s = get_repeat_cv_scores(X, y, model, nfolds, nrepeats)\n",
    "        scores.append(mean_s)\n",
    "\n",
    "    best_c = c_grid[scores.index(min(scores))]\n",
    "    print('\\nbest C:', best_c)\n",
    "    \n",
    "    params = {'C':best_c}\n",
    "    model = get_wrapper_multi_output_regression_model(regtype, params)\n",
    "    mean_s, std_s = get_repeat_cv_scores(X, y, model, nfolds, nrepeats)\n",
    "    print('MAE of %s in gridsearch:\\t%.3f (%.3f)' % (model.__class__.__name__, mean_s, std_s))\n",
    "    \n",
    "    # train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # test \n",
    "    yhat = model.predict(X_test)\n",
    "\n",
    "    # save predictions\n",
    "\n",
    "    pred_df.loc[testset_indices, truthcolnames] = y_test\n",
    "    pred_df.loc[testset_indices, predcolnames ] = yhat\n",
    "    fold_count += 1\n",
    "\n",
    "print(pred_df.head())\n",
    "outputcsvpath = os.path.join(savedir, estimator.__class__.__name__+'_predictions.csv')\n",
    "pred_df.to_csv(outputcsvpath)\n",
    "print(outputcsvpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e95a9",
   "metadata": {},
   "source": [
    "#### plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eea432",
   "metadata": {},
   "outputs": [],
   "source": [
    "predDir = os.path.join(output_dir, 'wrapper_multi_output_regression')\n",
    "figDir = output_dir\n",
    "for csv in os.listdir(predDir):\n",
    "    if '_predictions.csv' in csv:\n",
    "        \n",
    "        csvpath = os.path.join(predDir, csv)\n",
    "        estimator = csv.split('_')[0]\n",
    "        df = pd.read_csv(csvpath)\n",
    "        df = df.rename(columns={'Unnamed: 0':indexcol})\n",
    "        df.set_index(indexcol, inplace=True)\n",
    "        #fig = plt.figure(figsize=(len(scorecols)*4, 3))\n",
    "        \n",
    "        for n, col in enumerate(y.columns.values):\n",
    "            \n",
    "            #ax = fig.add_subplot( 1, 3, n+1)\n",
    "            g = sns.lmplot(y=col, x=col+'_pred', data=df)\n",
    "            r, p = stats.pearsonr(df[col], df[col+'_pred'])\n",
    "            g.fig.text(.8, .2, 'r={:.2f}, p={:.2g}'.format(r, p))\n",
    "            plt.show()\n",
    "            \n",
    "            figname = '-'.join([s for s in ['wrapper', estimator, col, 'lmplot.jpg']])\n",
    "            g.fig.savefig(os.path.join(figDir, figname), bbox_inches='tight', pad_inches=1, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453f17a4",
   "metadata": {},
   "source": [
    "## Chain Multioutput Regression\n",
    "train chain regression model using support vector regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172aafbc",
   "metadata": {},
   "source": [
    "#### get cross validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9706558",
   "metadata": {},
   "outputs": [],
   "source": [
    "regtype = 'svr'\n",
    "orders = [[0,1,2], [0,2,1], [1,0,2], [1,2,0], [2,0,1],[2,1,0]]\n",
    "scores = []\n",
    "params = {'C':best_c}\n",
    "for order in orders:\n",
    "    model = get_chain_multi_output_regression_model(regtype, params, order)\n",
    "    ms, _ = get_repeat_cv_scores(X, y, model, nfolds, nrepeats)\n",
    "    scores.append(ms)\n",
    "    print(ms)\n",
    "\n",
    "best_order = orders[scores.index(min(scores))]\n",
    "print('\\n-----best order:',best_order)\n",
    "print('->'.join(a for a in [targetcols[best_order[0]], \n",
    "                            targetcols[best_order[1]], \n",
    "                            targetcols[best_order[2]]]))\n",
    "\n",
    "model = get_chain_multi_output_regression_model(regtype, params, best_order)\n",
    "_, _ = get_repeat_cv_scores(X, y, model, nfolds, nrepeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a421d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = os.path.join(output_dir, 'chain_multi_output_regression')\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "regtype='svr'\n",
    "estimator = get_base_model(regtype)\n",
    "\n",
    "c_grid = [0.1, 0.2, 0.5, 1, 2, 5, 10]\n",
    "order = best_order\n",
    "fold_count = 0\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "truthcolnames = list(y.columns.values) \n",
    "predcolnames = [x + '_pred' for x in truthcolnames]\n",
    "pred_df = pd.DataFrame(index=X.index.values, columns=truthcolnames+predcolnames)\n",
    "\n",
    "for train_ix, test_ix in cv_outer.split(X, y):\n",
    "\n",
    "    print('\\nfold', fold_count)\n",
    "    X_train = X.iloc[train_ix]\n",
    "    X_test  = X.iloc[test_ix]\n",
    "    y_train = y.iloc[train_ix]\n",
    "    y_test  = y.iloc[test_ix]\n",
    "    testset_indices = X.index.values[test_ix]\n",
    "\n",
    "    # tuning is a bit manual in this case\n",
    "    # havenot found a way to make it work the traditional way (above)\n",
    "    scores = []\n",
    "    for c in c_grid:\n",
    "        params = {'C':c}\n",
    "        model = get_chain_multi_output_regression_model(regtype, params, best_order)\n",
    "        mean_s, std_s = get_repeat_cv_scores(X, y, model, nfolds, nrepeats)\n",
    "        scores.append(mean_s)\n",
    "\n",
    "    best_c = c_grid[scores.index(min(scores))]\n",
    "    print('\\nbest C:', best_c)\n",
    "    \n",
    "    params = {'C':best_c}\n",
    "    model = get_wrapper_multi_output_regression_model(regtype, params)\n",
    "    mean_s, std_s = get_repeat_cv_scores(X, y, model, nfolds, nrepeats)\n",
    "    print('MAE of %s in gridsearch:\\t%.3f (%.3f)' % (model.__class__.__name__, mean_s, std_s))\n",
    "    \n",
    "    # train\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # test \n",
    "    yhat = model.predict(X_test)\n",
    "\n",
    "    # save predictions\n",
    "\n",
    "    pred_df.loc[testset_indices, truthcolnames] = y_test\n",
    "    pred_df.loc[testset_indices, predcolnames ] = yhat\n",
    "    fold_count += 1\n",
    "\n",
    "print(pred_df.head())\n",
    "outputcsvpath = os.path.join(savedir, estimator.__class__.__name__+'_predictions.csv')\n",
    "pred_df.to_csv(outputcsvpath)\n",
    "print(outputcsvpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc2a9b",
   "metadata": {},
   "source": [
    "#### plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214951b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predDir = os.path.join(output_dir, 'chain_multi_output_regression')\n",
    "figDir =  output_dir\n",
    "for csv in os.listdir(predDir):\n",
    "    if '_predictions.csv' in csv:\n",
    "        estimatorname= csv.split('_')[0]\n",
    "        csvpath = os.path.join(predDir, csv)\n",
    "        estimator = csv.split('_')[0]\n",
    "        df = pd.read_csv(csvpath)\n",
    "        df = df.rename(columns={'Unnamed: 0':indexcol})\n",
    "        df.set_index(indexcol, inplace=True)\n",
    "        #fig = plt.figure(figsize=(len(scorecols)*4, 3))\n",
    "        \n",
    "        for n, col in enumerate(y.columns.values):\n",
    "            \n",
    "            #ax = fig.add_subplot( 1, 3, n+1)\n",
    "            g = sns.lmplot(y=col, x=col+'_pred', data=df)\n",
    "            r, p = stats.pearsonr(df[col], df[col+'_pred'])\n",
    "            g.fig.text(.8, .2, 'r={:.2f}, p={:.2g}'.format(r, p))\n",
    "            plt.title(estimatorname)\n",
    "            plt.show()\n",
    "            \n",
    "            figname = '-'.join([s for s in ['chain', estimatorname, col, 'lmplot.jpg']])\n",
    "            g.fig.savefig(os.path.join(figDir, figname), bbox_inches='tight', pad_inches=1, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d7883",
   "metadata": {},
   "source": [
    "### save direct multioutput random forest regressor model, trained on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9473a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train and all data, save out the model..')\n",
    "\n",
    "regtype = 'rfr'\n",
    "estimator, paramgrd = get_param_grid(regtype)\n",
    "print('tuning params for %s..' % estimator.__class__.__name__)\n",
    "best_params = get_best_params(X, y, estimator, paramgrd, nfolds)\n",
    "\n",
    "model = get_direct_multi_output_regression_model(regtype, best_params)\n",
    "model.fit(X, y)\n",
    "\n",
    "# save model to file\n",
    "modelfullpath = os.path.join(output_dir, 'rfr_' + '-'.join([t for t in targetcols]) + '-wSex.sav')\n",
    "pickle.dump(model, open(modelfullpath, 'wb'))\n",
    "print(modelfullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc3173",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
